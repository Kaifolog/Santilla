{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "import mlflow\n",
    "from os import environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbf5bbef32e4d4ebd6c34b186c02de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\utils\\Python3\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ktoto\\.cache\\huggingface\\hub\\models--sergeyzh--rubert-tiny-turbo. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fda5b920134dbdba60dfcc1f1766c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/117M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sergeyzh/rubert-tiny-turbo and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"sergeyzh/rubert-tiny-turbo\"\n",
    "model_max_length = 50   # reasonable length for my dataset\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name, model_max_length=model_max_length)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f007f682123541f093eec3a2957771e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638054f0aeab4257bd87a579e8db9830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/113483 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8801d0df2eb14284bd82f237770a2e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28371 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and preprocess dataset\n",
    "dataset = (\n",
    "    load_dataset(\"json\", data_files=\"../datasets/author.json\")[\n",
    "        \"train\"\n",
    "    ]\n",
    "    .train_test_split(test_size=0.2)\n",
    ")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Use DataCollatorWithPadding to handle different lengths of input sequences\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "    'accuracy': acc,\n",
    "    'f1': f1,\n",
    "    'precision': precision,\n",
    "    'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # for using with imbalanced classes https://discuss.huggingface.co/t/how-can-i-use-class-weights-when-training/1067\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([0.5, 0.5]))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = copy.deepcopy(control)\n",
    "            self._trainer.evaluate(\n",
    "                eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\"\n",
    "            )\n",
    "            return control_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ[\"MLFLOW_EXPERIMENT_NAME\"] = \"rubert-santilla-oversampled-definit-min3tokens\"\n",
    "environ[\"MLFLOW_FLATTEN_PARAMS \"] = \"True\"\n",
    "# environ[\"HF_MLFLOW_LOG_ARTIFACTS\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc6c8e69d2d47908fa9b1a11b8e7ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11039 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6105, 'grad_norm': 3.525597095489502, 'learning_rate': 9.523905385002517e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a0cb55f4cf45b5b333a5f4e6c551ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5300548672676086, 'eval_accuracy': 0.7249656339219626, 'eval_f1': 0.7239315038611096, 'eval_precision': 0.7279685766049728, 'eval_recall': 0.7249656339219626, 'eval_runtime': 4.7987, 'eval_samples_per_second': 5912.253, 'eval_steps_per_second': 82.314, 'epoch': 1.0}\n",
      "{'loss': 0.4677, 'grad_norm': 7.616848468780518, 'learning_rate': 7.93658782083543e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4ff8165b994d0195405011c725e7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48414382338523865, 'eval_accuracy': 0.762962179690529, 'eval_f1': 0.7620396995758699, 'eval_precision': 0.7666545774546514, 'eval_recall': 0.762962179690529, 'eval_runtime': 4.6793, 'eval_samples_per_second': 6063.068, 'eval_steps_per_second': 84.414, 'epoch': 2.0}\n",
      "{'loss': 0.3611, 'grad_norm': 10.366071701049805, 'learning_rate': 6.350276799194767e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab2f72d91134098ab73e9996228d18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.476492315530777, 'eval_accuracy': 0.783299848436784, 'eval_f1': 0.7831589052471983, 'eval_precision': 0.7838623345735832, 'eval_recall': 0.783299848436784, 'eval_runtime': 6.7825, 'eval_samples_per_second': 4182.965, 'eval_steps_per_second': 58.238, 'epoch': 3.0}\n",
      "{'loss': 0.2876, 'grad_norm': 5.685488700866699, 'learning_rate': 4.76295923502768e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a579bbd22c714cafa44c566a3a797162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5009725689888, 'eval_accuracy': 0.7935215536991999, 'eval_f1': 0.7931633639430523, 'eval_precision': 0.7952655497404355, 'eval_recall': 0.7935215536991999, 'eval_runtime': 4.6507, 'eval_samples_per_second': 6100.392, 'eval_steps_per_second': 84.934, 'epoch': 4.0}\n",
      "{'loss': 0.2351, 'grad_norm': 7.960174083709717, 'learning_rate': 3.1766482133870155e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d8cea1d79d45b79fc5fc6428d9f899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5475253462791443, 'eval_accuracy': 0.798949631666138, 'eval_f1': 0.7984637843378217, 'eval_precision': 0.8014956208909574, 'eval_recall': 0.798949631666138, 'eval_runtime': 5.755, 'eval_samples_per_second': 4929.806, 'eval_steps_per_second': 68.636, 'epoch': 5.0}\n",
      "{'loss': 0.1983, 'grad_norm': inf, 'learning_rate': 1.591343734272773e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25592760885e41dcba09793043c86491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.603981614112854, 'eval_accuracy': 0.8036727644425646, 'eval_f1': 0.8030118716983097, 'eval_precision': 0.8073653170324666, 'eval_recall': 0.8036727644425646, 'eval_runtime': 5.7584, 'eval_samples_per_second': 4926.873, 'eval_steps_per_second': 68.595, 'epoch': 6.0}\n",
      "{'loss': 0.1738, 'grad_norm': 6.061467170715332, 'learning_rate': 4.0261701056869654e-08, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2d847a8c074da8b51198ff4e9013bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6404132843017578, 'eval_accuracy': 0.8033555391068344, 'eval_f1': 0.8027310640973283, 'eval_precision': 0.806821482472322, 'eval_recall': 0.8033555391068344, 'eval_runtime': 4.8606, 'eval_samples_per_second': 5836.965, 'eval_steps_per_second': 81.266, 'epoch': 7.0}\n",
      "{'train_runtime': 493.9659, 'train_samples_per_second': 1608.17, 'train_steps_per_second': 22.348, 'train_loss': 0.3334335187539986, 'epoch': 7.0}\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=72,\n",
    "    per_device_eval_batch_size=72,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=7,\n",
    "    weight_decay=0.05,\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b890cf232246cf811eb3da9e409296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6404132843017578,\n",
       " 'eval_accuracy': 0.8033555391068344,\n",
       " 'eval_f1': 0.8027310640973283,\n",
       " 'eval_precision': 0.806821482472322,\n",
       " 'eval_recall': 0.8033555391068344,\n",
       " 'eval_runtime': 4.9179,\n",
       " 'eval_samples_per_second': 5768.914,\n",
       " 'eval_steps_per_second': 80.319,\n",
       " 'epoch': 7.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0032, 0.9968]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"если харрис изберут я реально пойду ленина читать\"\n",
    "\n",
    "model.eval()\n",
    "\n",
    "inputs = tokenizer(example, return_tensors=\"pt\").to('cuda')\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "print(nn.functional.softmax(logits, dim=1))\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
